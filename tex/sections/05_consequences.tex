% sections/05_consequences.tex
%
% Consequences of the Modelling Choices

\section{Consequences}
\label{sec:consequences}

\subsection{Consequence 1: Path Complexity $\mathcal{O}(n \log n)$}
\label{subsec:cons-path}

\begin{choice}[Scale-invariant branching regime]
\label{choice:scale-invariant}
Let $V$ be a finite family of Distinctions. For each step index $t \ge 1$, let
$m_t$ denote the number of distinct successor positions (effective neighbours)
available from the current position in $V$. Assume there exists a constant
$c > 0$ such that
\[
  m_t \le c\, t
  \quad
  \text{for all } t.
\]
This expresses a scale-invariant branching regime after possible clustering of
symmetric nodes into aggregate positions.
\end{choice}

\begin{consequence}[Nonlinear Memory path and $\mathcal{O}(n\log n)$ growth]
\label{cons:path-onlogn}
Let $N_n$ be the number of distinct Memory paths of length $n$ supported by
the branching regime in Choice~\ref{choice:scale-invariant}. Then
\[
  N_n \le \prod_{t=1}^n m_t \le \prod_{t=1}^n (c t) = c^n n!,
\]
and hence
\[
  \log_3 N_n = \mathcal{O}(n \log n)
  \quad\text{as } n \to \infty.
\]
\end{consequence}

\noindent
\textbf{Derivation.}
The bound $N_n \le \prod_{t=1}^n m_t$ follows by counting choices at each step
along a path. Under Choice~\ref{choice:scale-invariant},
$N_n \le c^n n!$. Taking the base-$3$ logarithm and using
$\log n! = \Theta(n \log n)$ yields $\log_3 N_n = \mathcal{O}(n \log n)$.

\begin{remark}
\label{rem:nonlinear-path}
The Memory path is generated by an underlying nonlinear update mechanism on
hidden states (such as recursive Null splittings
$\mathcal{N} = (\mathcal{N},\mathcal{N},\dots)$). The Markov description at
the level of Distinctions provides a stochastic representation of this
mechanism. Consequence~\ref{cons:path-onlogn} shows that, under the
scale-invariant branching regime of Choice~\ref{choice:scale-invariant}, the
number of distinguishable Memory paths grows on the order of
$\mathcal{O}(n \log n)$ trits.
\end{remark}

\subsection{Consequence 2: Null Clustering and Parallelism}
\label{subsec:cons-cluster}

\begin{definition}[Interior divergence of a Region]
\label{def:interior-div}
For any Region $R \subseteq V$, the interior divergence is
\[
  D(R) := \sum_{i \in R} \mathrm{div}(i).
\]
\end{definition}

\begin{consequence}[Null clusters and parallel additivity]
\label{cons:null-cluster}
For any Region $R \subseteq V$,
\[
  D(R) = \sum_{i\in R} \mathrm{div}(i)
       = \sum_{\substack{i\in R \\ j\notin R}} \phi_{ij},
\]
by the AFC Stokes identity. If $R_1,\dots,R_k$ are pairwise disjoint Regions,
then
\[
  D\Bigl(\bigcup_{\ell=1}^k R_\ell\Bigr)
  = \sum_{\ell=1}^k D(R_\ell).
\]
Any finite collection of positions $C \subseteq V$ may therefore be treated as
a single effective Null cluster with aggregate divergence $D(C)$, and the form
of the AFC Stokes identity and the additivity of $D(\cdot)$ are preserved
under such clustering.
\end{consequence}

\subsection{Consequence 3: Isotropic Ignorance and Topology}
\label{subsec:cons-isotropic}

\begin{choice}[Isotropic kernel on indistinguishable positions]
\label{choice:isotropic}
Let $V$ be a finite family of Distinctions and let $\sim$ be an equivalence
relation on $V$ expressing indistinguishability in the model (no internal
Distinctions within an equivalence class). A Markov Kernel $P$ on $V$ is
called isotropic with respect to $\sim$ if, for every permutation
$\pi : V \to V$ that preserves each equivalence class,
\[
  P_{ij} = P_{\pi(i)\,\pi(j)} \quad \text{for all } i,j \in V.
\]
\end{choice}

\begin{consequence}[Isotropic topology under stochastic ignorance]
\label{cons:isotropic-topology}
Let $P$ be isotropic with respect to $\sim$ as in
Choice~\ref{choice:isotropic}, and let $\phi_{ij}$ and $\mathrm{div}(i)$ be
defined as in Choices~\ref{choice:flux} and \ref{choice:divergence}. Then for
any permutation $\pi$ that preserves each equivalence class,
\[
  \phi_{ij} = \phi_{\pi(i)\,\pi(j)},
  \qquad
  \mathrm{div}(i) = \mathrm{div}(\pi(i))
\]
for all $i,j \in V$. In particular, the adjacency pattern defined by nonzero
fluxes and the AFC Stokes identity
\[
  \sum_{i\in R} \mathrm{div}(i)
  =
  \sum_{\substack{i\in R \\ j\notin R}} \phi_{ij}
\]
are unchanged under any relabelling that preserves indistinguishability, so
the induced topology is isotropic relative to the declared ignorance.
\end{consequence}

\begin{remark}
\label{rem:isotropic-null}
If all positions in an equivalence class $E \subseteq V$ are
indistinguishable in the model (no internal Distinctions), then $E$ can be
treated as a single Null cluster without breaking isotropy. The symmetry
condition in Choice~\ref{choice:isotropic} ensures that grouping $E$ into a
single effective node preserves the flux pattern up to overall scaling, so the
AFC Stokes identity and the Consequences in
Subsections~\ref{subsec:cons-path} and \ref{subsec:cons-cluster} remain valid
under isotropic Null clustering.
\end{remark}
